{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as stat\n",
    "import sys\n",
    "import csv\n",
    "from random import randint\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script converts a raw voltage reading into a time frequency power reading across a specified frequency range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THIS IS THE ONLY CELL THAT WILL BE ALTERED AFTER EXTRACTION HAS BEGUN\n",
    "\n",
    "auth_user = \"Keaton\"\n",
    "outfile = auth_user + \".csv\"\n",
    "song_id = 1\n",
    "\n",
    "total_trials = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Sensor(Enum):\n",
    "    AF3 = 0\n",
    "    F7 = 1\n",
    "    F3 = 2\n",
    "    FC5 = 3\n",
    "    T7 = 4\n",
    "    P7 = 5\n",
    "    O1 = 6\n",
    "    O2 = 7\n",
    "    P8 = 8\n",
    "    T8 = 9\n",
    "    FC6 = 10\n",
    "    F4 = 11\n",
    "    F8 = 12\n",
    "    AF4 = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global settings\n",
    "\n",
    "silent_dir = \"silent/\"\n",
    "music_dir = \"music/\"\n",
    "alpha_lower_freq = 8\n",
    "beta_lower_freq = 13\n",
    "beta_upper_freq = 30\n",
    "\n",
    "# holds the time intervals that will be extracted\n",
    "# alpha values placed first\n",
    "# beta values placed second\n",
    "# order determined by sensor arrays \n",
    "time_intervals = []\n",
    "interval_seconds = 15     # seconds\n",
    "sample_time_seconds = 0.5 # seconds \n",
    "points_per_row = 0                  # dynamically calculated\n",
    "csv_needs_header = True\n",
    "\n",
    "# used to denote what sensors are being recorded\n",
    "alpha_sensors = [Sensor.AF4, Sensor.P8, Sensor.FC5, Sensor.F3, Sensor.AF3, Sensor.F7, Sensor.T8, Sensor.FC6, Sensor.F4, Sensor.F8]\n",
    "beta_sensors = [Sensor.AF4, Sensor.P8, Sensor.FC5, Sensor.F3, Sensor.AF3, Sensor.F7, Sensor.T8, Sensor.FC6, Sensor.F4, Sensor.F8]    \n",
    "\n",
    "# names of participants \n",
    "names = [\"Keaton\", \"Alyse\", \"Richard\", \"Morty\", \"Jay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section finds the two files to be analyzed based off of the name and trial number\n",
    "    1. silent reading\n",
    "    2. music reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TagError(Exception):\n",
    "    pass\n",
    "\n",
    "def find_filename_by_tag(tag, dir_path):\n",
    "    \"\"\"\n",
    "    function for finding a single file with a given tag\n",
    "    \"\"\"\n",
    "    \n",
    "    tag_len = len(tag)\n",
    "\n",
    "    filenames = []\n",
    "\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename[0:tag_len] == tag:\n",
    "            filenames.append(filename)\n",
    "\n",
    "    # check to make sure only one file matched the tag\n",
    "    # if this is not the case, there is an error\n",
    "    if len(filenames) != 1:\n",
    "        print(\"Error with file lookup: Tag {}\".format(tag))\n",
    "        print(\"Total files found: {}\".format(len(filenames)))\n",
    "        for filename in filenames:\n",
    "            print(filename)\n",
    "        raise TagError(\"Tag Failed to Locate a Single File\")    \n",
    "        \n",
    "    return filenames[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section generates frequency power readings from the two files using the MNE library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_raw(raw):\n",
    "    \"\"\"\n",
    "    prepares a MNE raw object created from an Emotiv generated EDF file to have time frequency analysis done on it\n",
    "    \"\"\"\n",
    "    # drop unnecessary channels\n",
    "    extra_ch = raw.ch_names[0:2] + raw.ch_names[16:40]\n",
    "    raw.drop_channels(extra_ch)\n",
    "    \n",
    "    # manually add stim channel\n",
    "    stim_data = np.zeros((1, len(raw.times)))\n",
    "    info = mne.create_info(['STI'], raw.info['sfreq'], ['stim'])\n",
    "    stim_raw = mne.io.RawArray(stim_data, info)\n",
    "    raw.add_channels([stim_raw], force_update_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_power(raw, l_freq, h_freq):\n",
    "    \"\"\"\n",
    "    converts a raw MNE object that has been created using an Emotiv Pro generated EDF \n",
    "    file into a set of the average power across the specified frequencies\n",
    "    \n",
    "    raw: raw object\n",
    "    l_freq: frequency lower bound\n",
    "    h_freq: frequency upper bound\n",
    "    \n",
    "    return an MNE TRAverage with the average frequency from l_freq to h_freq\n",
    "    \"\"\"\n",
    "    # define time interval over which to extract\n",
    "    tmin = 0    # starting second\n",
    "    tmax = 39   # ending second\n",
    "    start, stop = raw.time_as_index([tmin, tmax])\n",
    "    \n",
    "    # define montage \n",
    "    montage = mne.channels.read_montage('standard_1020')\n",
    "    raw.set_montage(montage)\n",
    "    \n",
    "    # add events \n",
    "    events = np.array([[0, 0, 1]]) \n",
    "    raw.add_events(events)\n",
    "    \n",
    "    # add picks\n",
    "    picks = mne.pick_types(raw.info, eeg=True, eog=False, meg=False, stim=False, \n",
    "            exclude='bads')\n",
    "    \n",
    "    # add epochs\n",
    "    event_id, tmin, tmax = 1, 0, 39\n",
    "    baseline = (None, 0)\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax,\n",
    "        picks=picks,\n",
    "        baseline=baseline,\n",
    "        preload=True)\n",
    "    \n",
    "    # extract the average power across the specified range of frequencies\n",
    "    freqs = np.logspace(*np.log10([l_freq, h_freq]), num=1)\n",
    "    n_cycles = freqs / 2\n",
    "    power, itc = mne.time_frequency.tfr_morlet(epochs, freqs=freqs, \n",
    "                                                n_cycles=n_cycles,\n",
    "                                                use_fft=True,\n",
    "                                                return_itc=True,\n",
    "                                                decim=3, \n",
    "                                                n_jobs=1)\n",
    "    \n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace values outside of a set critical value with the channel average    \n",
    "def clean_channel(power, sensor_id):\n",
    "    avg = stat.mean(power.data[sensor_id][0])\n",
    "    std = stat.mean(power.data[sensor_id][0])\n",
    "    outliers = []\n",
    "    crit = 5\n",
    "    \n",
    "#     print(Sensor(sensor_id).name)\n",
    "    for i in range(len(power.data[sensor_id][0])):\n",
    "        z = (power.data[sensor_id][0][i] - avg) / std\n",
    "        if z >= crit:\n",
    "#             print(\"value: {}\".format(power.data[sensor_id][0][i]))\n",
    "#             print(\"time: {}\".format(power.times[i]))\n",
    "#             print(\"z score: {}\".format(z))\n",
    "#             print()\n",
    "            outliers.append(i)\n",
    "    \n",
    "    # remove points and recalculate average\n",
    "    avg = avg * len(power.data[sensor_id][0])\n",
    "    for outlier in outliers:\n",
    "        avg -= power.data[sensor_id][0][outlier]\n",
    "    \n",
    "    avg = avg / (len(power.data[sensor_id][0]) - len(outliers))\n",
    "    \n",
    "    # set all outliers to the new average\n",
    "    for outlier in outliers:\n",
    "        power.data[sensor_id][0][outlier] = avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the data from the music reading with the following processes\n",
    "    1. any data point with a z score outside of a set critical value will be replaced with the average of the reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_time_interval(music_power, sensor, time_length):\n",
    "    \"\"\"\n",
    "    finds the four time intervals across the power array that correspond to the maximum change in the frequency band\n",
    "    \n",
    "    music_power: the MNE AverageTF Power object created from Emotiv Pro \n",
    "    sensor: integer corresponding to the index of the sensor's data in music_power\n",
    "    time_length: a float representing the length of the time interval to be calculated\n",
    "    \n",
    "    returns an array of tuples\n",
    "        each has a starting index and an ending index\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    lower = 0\n",
    "    upper = 0\n",
    "    \n",
    "    total = 0\n",
    "    maximum = 0\n",
    "    \n",
    "    intervals = []\n",
    "    \n",
    "    # size the interval\n",
    "    while music_power.times[end] - music_power.times[start] < time_length:\n",
    "        total += music_power.data[sensor][0][end]\n",
    "        end += 1\n",
    "    \n",
    "    upper = end\n",
    "    maximum = total\n",
    "    \n",
    "    while end < len(music_power.data[sensor][0]):\n",
    "        total += music_power.data[sensor][0][end]\n",
    "        total -= music_power.data[sensor][0][start]\n",
    "        start += 1\n",
    "        end += 1\n",
    "        \n",
    "        if total > maximum:\n",
    "            lower = start\n",
    "            upper = end\n",
    "            maximum = total\n",
    "            \n",
    "        \n",
    "        \n",
    "    return (lower, upper)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(name, song, trial, is_user):\n",
    "    \"\"\"\n",
    "    extract the trial information from a user\n",
    "    @param name: the name associated with the trial file\n",
    "    @param song: songs are numbered 1 - 5\n",
    "    @param trial: trials are numbered 1 - 3\n",
    "    \"\"\"\n",
    "    \n",
    "    global csv_needs_header\n",
    "    global points_per_row\n",
    "    \n",
    "    music_tag = \"{}_{}_{}_\".format(name, song, trial)\n",
    "    silent_tag= \"{}_s_{}_\".format(auth_user, 0)\n",
    "    \n",
    "    # Create tag to locate files in respective directories\n",
    "    silent_filename = \"\"\n",
    "    music_filename = \"\"\n",
    "\n",
    "    try:\n",
    "        silent_filename = find_filename_by_tag(silent_tag, silent_dir)\n",
    "        music_filename = find_filename_by_tag(music_tag, music_dir)\n",
    "    except TagError:\n",
    "        print(\"A Tag Error Occured\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(silent_filename)\n",
    "    print(music_filename)\n",
    "\n",
    "    # read in files\n",
    "    raw_silent = mne.io.read_raw_edf(silent_dir + silent_filename, preload=True)\n",
    "    raw_music = mne.io.read_raw_edf(music_dir + music_filename, preload=True)\n",
    "\n",
    "    preprocess_raw(raw_silent)\n",
    "    preprocess_raw(raw_music)\n",
    "\n",
    "    print(raw_music.ch_names)\n",
    "    print(raw_silent.ch_names)\n",
    "\n",
    "    # extra average power over alpha and beta frequencies for each file\n",
    "    alpha_silent = get_power(raw_silent, alpha_lower_freq, beta_lower_freq)\n",
    "    beta_silent = get_power(raw_silent, beta_lower_freq, beta_upper_freq)\n",
    "    alpha_music = get_power(raw_music, alpha_lower_freq, beta_lower_freq)\n",
    "    beta_music = get_power(raw_music, beta_lower_freq, beta_upper_freq)\n",
    "\n",
    "    # test code\n",
    "    # plt.plot(alpha_silent.times[:], alpha_silent.data[0][0][:])\n",
    "    # plt.title(alpha_silent.ch_names[0])\n",
    "    # plt.show()\n",
    "\n",
    "    # print(beta_music.ch_names)\n",
    "\n",
    "    alpha_silent_means = []\n",
    "    beta_silent_means = []\n",
    "\n",
    "    alpha_silent_stds = []\n",
    "    beta_silent_stds = []\n",
    "\n",
    "    # power.data[ch][freq][times]\n",
    "\n",
    "    for i in range(len(alpha_silent.data)):\n",
    "        clean_channel(alpha_silent, i)\n",
    "        alpha_silent_means.append(stat.mean(alpha_silent.data[i][0]))\n",
    "        alpha_silent_stds.append(stat.stdev(alpha_silent.data[i][0]))\n",
    "\n",
    "    for i in range(len(beta_silent.data)):\n",
    "        clean_channel(beta_silent, i)\n",
    "        beta_silent_means.append(stat.mean(beta_silent.data[i][0]))\n",
    "        beta_silent_stds.append(stat.stdev(beta_silent.data[i][0]))\n",
    "\n",
    "    # print(alpha_silent_means)\n",
    "    # print(alpha_silent_stds)\n",
    "    # print(beta_silent_means)\n",
    "    # print(beta_silent_stds)    \n",
    "\n",
    "    for sensor in alpha_sensors:\n",
    "        clean_channel(alpha_music, sensor.value)\n",
    "\n",
    "    for sensor in beta_sensors:\n",
    "        clean_channel(beta_music, sensor.value)  \n",
    "\n",
    "    # extract time intervals from the first trial only\n",
    "    # this was the registration phase of our model and will be used\n",
    "    # for model metadata\n",
    "\n",
    "    if len(time_intervals) == 0:\n",
    "\n",
    "        for sensor in alpha_sensors:\n",
    "            time_intervals.append(get_time_interval(alpha_music, sensor.value, interval_seconds))\n",
    "\n",
    "        for sensor in beta_sensors:\n",
    "            time_intervals.append(get_time_interval(beta_music, sensor.value, interval_seconds))\n",
    "\n",
    "        points_per_row = floor((time_intervals[0][1] - time_intervals[0][0]) / (interval_seconds / sample_time_seconds))\n",
    "\n",
    "    print(\"Time Interval Indices: {}\".format(time_intervals))\n",
    "    print(\"Length of Interval: {}\".format(interval_seconds))\n",
    "    print(\"Length of Sub-Interval: {}\".format(sample_time_seconds))\n",
    "    print(\"Points Per Sample: {}\".format(points_per_row))\n",
    "    \n",
    "    if csv_needs_header:\n",
    "        write_header()\n",
    "        csv_needs_header = False\n",
    "        \n",
    "    write_data_points(alpha_music, alpha_silent_means, alpha_silent_stds, beta_music, beta_silent_means, beta_silent_stds, is_user)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_header():\n",
    "    with open(outfile, 'w', newline='') as csvfile:\n",
    "        row = []\n",
    "        w = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        # create 1 column for each sensor\n",
    "        for sensor in alpha_sensors:\n",
    "            row.append(\"{}_alpha\".format(sensor.name))\n",
    "        \n",
    "        for sensor in beta_sensors:\n",
    "            row.append(\"{}_beta\".format(sensor.name))\n",
    "        \n",
    "        # write header for each time point\n",
    "#         for i in range(len(alpha_sensors)):\n",
    "#             for j in range(points_per_row):\n",
    "#                 row.append(\"{}_alpha_{}\".format(alpha_sensors[i].name, j))\n",
    "\n",
    "#         for i in range(len(beta_sensors)):\n",
    "#             for j in range(points_per_row):\n",
    "#                 row.append(\"{}_beta_{}\".format(beta_sensors[i].name, j))\n",
    "\n",
    "        row.append(\"is_user\")\n",
    "\n",
    "        w.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate and write to CSV file\n",
    "\n",
    "def write_data_points(alpha_music, alpha_silent_means, alpha_silent_stds, beta_music, beta_silent_means, beta_silent_stds, is_user):\n",
    "\n",
    "    with open(outfile, 'a', newline='') as csvfile:\n",
    "\n",
    "        w = csv.writer(csvfile, delimiter=',')\n",
    "        \n",
    "        row = []\n",
    "        \n",
    "        offset = 0\n",
    "        \n",
    "        sum = 0\n",
    "\n",
    "        # record the z score of each data point for the sample\n",
    "        while time_intervals[0][0] + offset + points_per_row < time_intervals[0][1]:\n",
    "            for i in range(len(alpha_sensors)):\n",
    "                sum = 0\n",
    "                \n",
    "                for j in range(points_per_row):\n",
    "                    sum += alpha_music.data[alpha_sensors[i].value][0][time_intervals[i][0] + offset + j]\n",
    "                    #row.append(abs(alpha_music.data[alpha_sensors[i].value][0][time_intervals[i][0] + offset + j] \n",
    "                    #              - alpha_silent_means[alpha_sensors[i].value]) / alpha_silent_stds[alpha_sensors[i].value])\n",
    "                row.append((sum / points_per_row - - alpha_silent_means[alpha_sensors[i].value]) / alpha_silent_stds[alpha_sensors[i].value] / points_per_row ** .5)\n",
    "                    \n",
    "            for i in range(len(beta_sensors)):\n",
    "                sum = 0\n",
    "                \n",
    "                for j in range(points_per_row):\n",
    "                    sum += beta_music.data[beta_sensors[i].value][0][time_intervals[i + len(alpha_sensors)][0] + offset + j]\n",
    "                    # append the deviation from the mean for the data point in question\n",
    "#                     row.append(abs(beta_music.data[beta_sensors[i].value][0][time_intervals[i + len(alpha_sensors)][0] + offset + j] \n",
    "#                                    - beta_silent_means[beta_sensors[i].value]) / beta_silent_stds[beta_sensors[i].value])                \n",
    "                row.append((sum / points_per_row - beta_silent_means[beta_sensors[i].value]) / (beta_silent_stds[beta_sensors[i].value] / points_per_row ** .5))\n",
    "    \n",
    "            row.append(is_user)        \n",
    "\n",
    "            offset += points_per_row\n",
    "\n",
    "            w.writerow(row)\n",
    "\n",
    "            row.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'silent\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-67b2f9a569b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# extract data for authorized user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msong_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# extract data for attackers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-dcd31cf55356>\u001b[0m in \u001b[0;36mextract\u001b[0;34m(name, song, trial, is_user)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msilent_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_filename_by_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmusic_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_filename_by_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmusic_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTagError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7978bd2cad5e>\u001b[0m in \u001b[0;36mfind_filename_by_tag\u001b[0;34m(tag, dir_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtag_len\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mfilenames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'silent\\\\'"
     ]
    }
   ],
   "source": [
    "attackers = []\n",
    "\n",
    "for name in names:\n",
    "    if name != auth_user:\n",
    "        attackers.append(name)\n",
    "        \n",
    "# print(attackers)\n",
    "\n",
    "# extract data for authorized user\n",
    "for i in range(total_trials):\n",
    "    extract(auth_user, song_id, i, 1)\n",
    "    \n",
    "# extract data for attackers \n",
    "for i in range(len(attackers)):\n",
    "    extract(attackers[i], song_id, randint(1, total_trials - 1), 0)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
